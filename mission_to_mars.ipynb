{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars (Web Scraping Homework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "from urllib.parse import urlsplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "Create a Jupyter Notebook file called mission_to_mars.ipynb and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "NASA Mars News\n",
    "Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up chrome driver and initiallize Browswer\n",
    "executable_path = {'executable_path':\"chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "# loading the webpage\n",
    "url = \"https://mars.nasa.gov/news\"\n",
    "browser.visit(url)\n",
    "\n",
    "# writing page to html using BeautifulSoup\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_title = 5 Hidden Gems Are Riding Aboard NASA's Perseverance Rover\n",
      "\n",
      "news_p = The symbols, mottos, and small objects added to the agency's newest Mars rover serve a variety of purposes, from functional to decorative.\n"
     ]
    }
   ],
   "source": [
    "# extracting news title and news paragraph\n",
    "title = [title for title in [tt.a.text for tt in soup.find_all(\"div\", class_=\"content_title\") if tt.a] if title != \"\"]\n",
    "# news_p = soup.find_all(\"div\", class_=\"article_teaser_body\")\n",
    "para = [para.text for para in soup.find_all(\"div\", class_=\"article_teaser_body\")]\n",
    "\n",
    "# latest headline:\n",
    "news_title = title [0]\n",
    "news_p = para [0]\n",
    "\n",
    "# print out title and paragraph\n",
    "print(f'new_title = {news_title}')\n",
    "print(\"\")\n",
    "print(f'news_p = {news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images - Featured Image\n",
    "\n",
    "JPL Mars Space Images - Featured Image\n",
    "Visit the url for JPL Featured Space Image here.\n",
    "https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
    "\n",
    "Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "\n",
    "Make sure to find the image url to the full size .jpg image.\n",
    "\n",
    "Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up chrome driver and initiallize Browswer\n",
    "executable_path = {'executable_path':\"chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "\n",
    "url_img = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/\n"
     ]
    }
   ],
   "source": [
    "base_url = \"{0.scheme}://{0.netloc}/\".format(urlsplit(url_img))\n",
    "print(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Xpath to graph the image\n",
    "xpath = \"//*[@id=\\\"page\\\"]/section[3]/div/ul/li[1]/a/div/div[2]/img\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use splinter to click on the mars featured image\n",
    "#to bring the full resolution image\n",
    "results = browser.find_by_xpath(xpath)\n",
    "img = results[0]\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov//spaceimages/images/largesize/PIA24275_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "#get image url using BeautifulSoup\n",
    "html_image = browser.html\n",
    "soup = bs(html_image, \"html.parser\")\n",
    "img_url = soup.find(\"img\", class_=\"fancybox-image\")[\"src\"]\n",
    "featured_image_url = base_url + img_url\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
